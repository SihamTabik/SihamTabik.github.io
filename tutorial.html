<!DOCTYPE html>
<html>
<body>

<h2>Building CNNs based-classifiers with TensorFlow </h2>	
<h2>Content:</h2><br>
<ol>  
<li>Prerequisites: Previous programming experience in Python and some familiarity with machine learning are necessary.	
<li>Install TensorFlow with virtual Python environment 
<li>First CNN classifcation model	
<li>Classify Imagenet		
<li>Retrain on New dataset
<li>Important terminology in DL
</ol>
	
<ol>
  <!-- Install -->	
	
  <li><h2> Install TensorFlow with virtual Python environment </h2></li>
  TensorFlow can be installed in Ubuntu, Mac and Windows.<br><br>
  
	
  TensorFlow can be installed using four different mecanisms. We will use the recomenaded virtualenv instalation. The steps are as follows: <br><br>
	
<ol>
  <li> Install pip and virtualenv by issuing the following command:<br>
<table>
   <tr  bgcolor="#CCFFFF"><td>	
<xmp> sudo apt-get install python-pip python-dev python-virtualenv</xmp>
	    </td>
   </tr>
</table>
  <li> Create a virtualenv environment by issuing the following command:<br>
<table>
   <tr  bgcolor="#CCFFFF"><td>	
<xmp> virtualenv --system-site-packages targetDirectory </xmp>
</td></tr></table>

The targetDirectory specifies the top of the virtualenv tree. Our instructions assume that targetDirectory is ~/tensorflow, but you may choose any directory.
<li> Activate the virtualenv environment by issuing one of the following commands:
<table><tr  bgcolor="#CCFFFF"><td>	
 <xmp> source ~/tensorflow/bin/activate # bash, sh, ksh, or zsh</xmp>
 <xmp> source ~/tensorflow/bin/activate.csh  # csh or tcsh</xmp>
</td> </tr></table> 
The preceding source command should change your prompt to the following:<br>
<table><tr  bgcolor="#CCFFFF"><td>	
<xmp> (tensorflow)$ </xmp>
</td> </tr></table>
	  
<li> Issue one of the following commands to install TensorFlow in the active virtualenv environment:<br>
<br> If you have 1) NVIDIA® GPU with Compute Capability 3.0 or higher and 2) cuDNN v5.1 v3 or greater then you can install  tensorflow-gpu, which os prepared to run on one and multiple NVIDIA GPUs.<br>	

<table><tr  bgcolor="#CCFFFF"><td>	
<xmp> (tensorflow)$ pip install --upgrade tensorflow-gpu  # for Python 2.7 and GPU</xmp>
<xmp> (tensorflow)$ pip3 install --upgrade tensorflow-gpu # for Python 3.n and GPU</xmp>
</td></tr></table>
	
If you don't have GPUs with the mentioned characteristics then:<br>
<table><tr  bgcolor="#CCFFFF"><td>		
<xmp> (tensorflow)$ pip install --upgrade tensorflow      # for Python 2.7</xmp>
<xmp> (tensorflow)$ pip3 install --upgrade tensorflow     # for Python 3.n</xmp>
</td> </tr></table>

<!-- Check installation is OK -->	
<li> Check the location where pip installed tensorflow packages <br>
<table><tr  bgcolor="#CCFFFF"><td>	
pip show tensorflow <br>
</td> </tr></table>
	
<!-- Check installation is OK -->	
<li> Check the installation has been done successfully <br>
Save the following short program as hello.py: <br>
	
<table><tr  bgcolor="#CCFFFF"><td>		
<xmp>import tensorflow as tf</xmp>
<xmp>hello = tf.constant('Hello, TensorFlow!')</xmp>
<xmp>sess = tf.Session()</xmp>
<xmp>print(sess.run(hello))</xmp>
</td> </tr></table>

Run this commandline in your shell as follows: <br>

<table><tr  bgcolor="#CCFFFF"><td>		
<xmp> (tensorflow)$ python hello.py</xmp>
</td> </tr></table>
	
	
If the system outputs the following, then you are ready to begin writing TensorFlow programs:<br>
<table><tr  bgcolor="#CCFFFF"><td>		
<xmp>Hello, TensorFlow!</xmp>
</td> </tr></table>


</ol> 
<li><h2>Building my first CNN</h2></li>
To get more familiar with CNNs, let's start with the classification of MNIST database. <br> 
The first successful CNN in MNIST classification is called LeNet. <br>
Let's implement a LeNet-5-like CNN shown in the figure. <br>

<img class="sealImage" alt="Image of Seal" src="LeNet-like-CNN.jpg">
<br>
<img src="LeNet-like-CNN.jpg" alt="LeNet-like-CNN">
	
<!-- Check installation is OK	
<table><tr  bgcolor="#CCFFFF"><td>	
<xmp>cd ./tensorflow/lib/python2.7/site-packages/tensorflow/models/image/mnist/</xmp>
</td> </tr></table>
-->	
complete lines 43-48 with the correct dimensions. 
<br> the code can be run as:
 	
<table><tr  bgcolor="#CCFFFF"><td>	
<xmp>python   convolutional.py # train on CPU/GPU depending on the installation</xmp>
</td> </tr></table>	

or<br> 
	

<table><tr  bgcolor="#CCFFFF"><td>	
<xmp>CUDA_VISIBLE_DEVICES=0,1 python   convolutional.py # train on selected GPUs with identifiers 0 and 1</xmp>
</td> </tr></table>	
	
	
<li><h2>Classify Imagenet</h2></li>	
	
<xmp> cd models/tutorials/image/imagenet</xmp>
<xmp> python classify_image.py</xmp>
If the model runs correctly, the script will produce the top five classes with their respective scores.<br>
If you wish to supply other JPEG images, you may do so by editing the <xmp> --image_file </xmp> argument.<br>

If you download the model data to a different directory, you will need to point <xmp>--model_dir</xmp> to the directory used.<br>

  <li><h2>Transfer Learning: Retrain on a New dataset</h2></li>
This consists of finetuning GoogLeNet's final layer on a new dataset, flower_photos, as follows: <br> 
Download new dataset <br>
 <table>
   <tr  bgcolor="#CCFFFF"><td>
       <xmp> cd ~ </xmp>
       <xmp> curl -O http://download.tensorflow.org/example_images/flower_photos.tgz </xmp>
       <xmp> tar xzf flower_photos.tgz </xmp> </font>

	 </td>
   </tr>
</table>
 Download retrain.py   <br>   
<table>
   <tr  bgcolor="#CCFFFF"><td>	
       <xmp> cd  ~/tensorflow/lib/python2.7/site-packages/tensorflow/examples/ </xmp>
       <xmp> mkdir image_retraining </xmp>
       <xmp> curl -O https://raw.githubusercontent.com/tensorflow/tensorflow/r1.1/tensorflow/examples/image_retraining/retrain.py </xmp>
 	 </td>
   </tr>
</table>

	   Have a look at retrain.py and costumize where you want to download the GoogLeNet, also called Inception model, bottelneck, . By default the model is downloaded in /tmp. 
<table>
        <tr  bgcolor="#CCFFFF"><td>	
	<xmp> python retrain.py --image_dir ~/flower_photos {add your args here} </xmp>
	</td>
   </tr>
</table>	
This script 1) loads the pre-trained GoogLeNet model, 2) removes the old top FC layer, also called Bottleneck, and 3) trains a new one
on the flower photos you've downloaded. None of the flower species were in the original ImageNet classes the full network was
trained on.  The magic of transfer learning, also called fine-tuning, is that lower layers that have been trained to distinguish 
	between some objects can be reused for many recognition tasks without any alteration.
<br><br>

To test the retrained model use this script<br>	
	
<a href="label_image.py">label_image.py</a><br>	
<table>
        <tr  bgcolor="#CCFFFF"><td>	
	<xmp>python label_image.py  $TEST_IMAGE_PATH  </xmp>
	</td>
   </tr>
</table>
	
<!--
2017-06-15 13:50:09.216886: Step 3999: Train accuracy = 95.0%<br>
2017-06-15 13:50:09.216944: Step 3999: Cross entropy = 0.186286<br>
2017-06-15 13:50:09.261670: Step 3999: Validation accuracy = 93.0% (N=100)<br>
Final test accuracy = 93.7% (N=378)<br>
Converted 2 variables to const ops.<br>
-->
<li><h2>Important terminology in DL</h2></li>	
	
<h1> batch size</h1> Convolutional Neural Networks (CNNs) do not process the images one-at-a-time. To increase their throughput, CNNs
process the data in batches. Suppose a CNN that is trained on  RGB (3-channel) images that are 256x256 pixels. 
	A single image can be represented by a 3 x 256 x 256 matrix. If you set your batch size to be 10, 
	that means you’re concatenating 10 images together into a 10 x 3 x 256 x 256 matrix. In practice, you’ll create 
	batches of data that are randomly selected from your training set. 
	This is the ‘stochastic’ part of stochastic gradient descent (SGD). During a single forward and backward pass of 
	training, the network will update its parameters according to what’s in the batch. This is why the selection has to be 
	random - if you feed in a batch of only dog images, the CNN will become a little more eager to classify images as 
	dogs after that training iteration.

Tuning the batch size is one of the aspects of getting training right - if your batch size is too small, then there will be a 
	lot of variance within a batch, and your training loss curve will bounce around a lot. But if it’s too large, your GPU will run out of memory to hold it, or training will progress too slowly to see if it’s the optimization is diverging early on.

I think you’ll also find the answers to this question helpful:

Intuitively, how does mini-batch size affect the performance of (stochastic) gradient descent?	
	
	
	
	
	
        </ol>      



<h2></h2>    
<h2></h2>

</body>
</html>
